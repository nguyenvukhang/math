\section{Plenary}\label{80eeafc}

All the proofs and results I don't want to write twice.

\textbf{1.x.x)} Real analysis \\
\textbf{2.x.x)} Calculus \\
\textbf{9.x.x)} General stuff \\

\Definition{1.1.1}{Monotone sequences}\label{d5142a8}

A sequence $\{x_n\}$ is said to be \textbf{increasing} if $x_0\leq
	x_1\leq x_2\leq\ldots$ and \textbf{decreasing} if $x_0\geq x_1\geq
	x_2\geq\ldots$ and \textbf{monotone} if it is either increasing or
decreasing.

\Theorem{1.1.2}{Monotone convergence theorem}\label{ca25eb7}

If $\{x_n\}$ is monotone and bounded, then $\{x_n\}$ converges.

$$
	\lim_{n\to\infty}=\begin{cases}
		\sup\{x_n:n\in\N\} & \text{if $\{x_n\}$ is increasing} \\
		\inf\{x_n:n\in\N\} & \text{if $\{x_n\}$ is decreasing}
	\end{cases}
$$

\Theorem{1.1.3}{Monotone subsequence theorem}\label{dddb70e}

Every sequence has a monotone subsequence.

\begin{proof}
	\def\xn{\{x_n\}}

	Let $\xn$ be a sequence. We call a term $x_p$ a \textbf{peak term}
	of $\xn$ if
	$$x_p\geq x_n\quad(\forall n\geq p)$$

	That is, all terms after $x_p$ never go above $x_p$ again. Then
	there are only two cases:

	\textbf{Case 1:} $\xn$ has infinitely many peak terms.

	Then the subsequence formed by all the peak terms form a decreasing
	subsequence of $\xn$.

	\textbf{Case 2:} $\xn$ has finitely many peak terms.

	Let $x_{p_1},x_{p_2},\ldots,x_{p_j}$ be \textbf{all} the peak terms.

	Let $n_1=p_j+1$ be the first term after the last peak term.

	Since $x_{n_1}$ is not a peak term. $\implies\exists n_2>n_1$ such
	that $x_{n_1}<x_{n_2}$.

	Since $x_{n_2}$ is not a peak term, $\implies\exists n_3>n_2$ such
	that $x_{n_2}<x_{n_3}$.

	Continuing indefinitely, we can form an increasing subsequence
	$\{x_{n_k}\}$.
\end{proof}

\Theorem{1.1.4}{Bolzano-Weierstrass Theorem}\label{d277ad0}

Every bounded sequence has a convergent subsequence.

\begin{proof}
	\def\xn{\{x_n\}}
	\def\xnk{\{x_{n_k}\}}

	Let $\xn$ be a bounded sequence. By the monotone subsequence
	theorem, $\xn$ has a monotone subsequence $\xnk$.

	Since $\xn$ is bounded, so is $\xnk$.

	Since $\xnk$ is both monotone and bounded, it follows from the
	\hyperref[ca25eb7]{monotone convergence theorem} that $\xnk$
	converges.
\end{proof}

% proof for MATH 378

\Theorem{1.1.5}{Monotone sequence with a convergent subsequence is\label{db9529b}
	convergent}\label{aaf3ba6}

Let $\{x_n\}$ be a monotone sequence with a subsequence $\{x_{n_k}\}$
that converges to $L$. Then $\{x_n\}$ converges to $L$.

\begin{proof}
	WLOG, assume that $\{x_n\}$ is decreasing.
	Given any $\epsilon>0$, we want to find a $N_\epsilon\in\N$ such that
	$$
		|x_n-L|<\epsilon\quad\forall(n\geq N_\epsilon)
	$$

	Since $\{x_{n_k}\}$ is decreasing and converges to $L$, we can find
	(and fix) a $k_\epsilon$ such that
	\begin{equation*}
		0<x_{n_k}-L<\epsilon\quad\forall(k\geq k_\epsilon)\tag*{($*$)}
	\end{equation*}
	So we take $N_\epsilon=n_{k_\epsilon}$. Then since $\{x_n\}$ is
	decreasing,
	$$
		x_n\leq x_{N_\epsilon}=x_{n_{k_\epsilon}}\quad\forall(n\geq N_\epsilon)
	$$
	Moreover, $L\leq x_n\leq x_{n_{k_\epsilon}}$, and hence
	$$0\leq x_n-L\leq x_{n_{k_\epsilon}}-L$$
	and from $(*)$, we have that this entire inequality $<\epsilon$, and hence
	$$0\leq x_n-L<\epsilon$$
	and finally
	$$|x_n-L|<\epsilon$$
\end{proof}

\Theorem{1.1.6}{Mean value theorem}\label{d37aa2b}

Let $f:[a,b]\to\R$ be continuous on the $[a,b]$, and differentiable on
$(a,b)$. Then there exists $c\in(a,b)$ such that
$$
	f'(c)=\frac{f(b)-f(a)}{b-a}
$$

Generalized to multiple variables, the mean value theorem can be
written as:

Let $f:[a,b]\to\R$, where $a,b\in\R^n$, and $[a,b]$ refers to the line
segment connecting $a$ and $b$, namely
$$
	[a,b]:=\{\lambda a+(1-\lambda)b\mid\lambda\in[0,1]\}
$$

Suppose $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$.
Then there exists $c\in[a,b]$ such that
$$
	\nabla f(c)^T(b-a)=f(b)-f(a)
$$

In some arguments, we use $f:[x,x+td]\to\R$ and write that there
exists $\eta\in[x,x+td]$ such that
$$
	\nabla f(\eta)^Td=\frac{f(x+td)-f(x)}t
$$

\Result{1.1.7}{Preprocessed limits}\label{ffc8953}

Let $k,\ell\in\N$ and $a,b,c\in\R$ be fixed.
\begin{enumerate}[label=(\alph*)]
	\def\li{\displaystyle\lim_{n\to\infty}}
	\item $\li\frac1{n^k}=0$
	\item $\li b^n=0$ \quad if \quad $|b|<1$
	\item $\li c^{\frac1n}=1$ \quad if \quad $c>0$
	\item $\li n^{\frac1n}=1$
	\item $\li \left(1+\frac1n\right)^n=e$
	\item $\li \left(1-\frac1n\right)^n=\frac1e$
	\item $\li \frac{n^k}{c^n}=0$ \quad if \quad $c>0$
\end{enumerate}

if $k<\ell$ and $1<a<b$, we have
$$
	n^k << n^\ell << a^n << b^n << n!
$$

\Theorem{1.1.8}{Bernoulli's inequality}\label{d44713f}
$$
	(1+x)^r\geq 1+rx
$$

This holds under any of the following conditions:
\begin{itemize}
	\item $r\in\Z,r\geq1$ and $x\in\R,x\geq-1$ (inequality is strict if
	      $x\neq0$ and $r\geq2$)
	\item $r\in\Z,r\geq0$ and $x\in\R,x\geq-2$
	\item $r\in\Z$, $r$ is even and $x\in\R$
	\item $r\in\R,r\geq1$ and $x\in\R,x\geq-1$ (inequality is strict if
	      $x\neq0$ and $r\neq1$)
\end{itemize}

and separately,
$$
	(1+x)^r\leq 1+rx
$$
for every $r\in\R,0\leq r\leq 1$ and $x\geq-1$.

\Result{1.1.9}{Limit to infinity of a rational function}\label{ccfddb1}

Let $P,Q$ be polynomial functions, where $Q$ is of a higher degree.
Then
$$
	\lim_{x\to\infty}\frac{P(x)}{Q(x)}=0
$$

\begin{compute}
	Consider the example of
	$$
		\lim_{x\to\infty}\frac{x^2 - 3x}{x^3 + 2x + 5}
	$$
	We can divide both numerator and denominator by $x^2$ to obtain
	$$
		\lim_{x\to\infty}\frac{1 - \frac3x}{x + \frac2x + \frac5{x^2}}
	$$
	And we can see that the numerator $\to1$ while the denominator
	$\to\infty$.
\end{compute}

\Result{1.1.10}{Limit of $\frac{e^x}x$ as $x\to\infty$}\label{b905ee7}
$$
	\lim_{x\to\infty}\frac{e^x}x=\infty
$$

\begin{proof}
	% TODO: add Taylor series
	Since $e^x$ can be written as a Taylor series
	$$
		e^x=1 + x + \frac{x^2}2 +\ldots
	$$
	We have $e^x\geq 1 + x + x^2$ and hence
	\begin{align*}
		\lim_{x\to\infty}\frac{e^x}x
		 & \geq\lim_{x\to\infty}\frac{1+x+\frac{x^2}2}x \\
		 & =\lim_{x\to\infty}\frac1x + 1 + \frac{x}2    \\
		 & = \infty
	\end{align*}
\end{proof}


\Result{1.1.11}{Limit of $\frac{\ln x}{x}$ as $x\to\infty$}\label{e2e1632}
$$
	\lim_{x\to\infty}\frac{\ln x}x = 0
$$

\begin{proof}
	Given any $\epsilon$, we have to find a $N\in\N$ such that
	$$
		n\geq N\implies\frac{\ln x}x<\epsilon
	$$

	But, if you've been paying attention,
	$$
		\frac{\ln x}x<\epsilon\iff\frac{e^{\epsilon x}}{\epsilon x}>\frac1\epsilon
	$$

	And since $\epsilon x\to+\infty$, using \hyperref[b905ee7]{Result
		1.1.10} with $\epsilon x$ as the limiting variable tells us that
	indeed there exists such an $N$, hence completing the proof.
\end{proof}

\Result{1.1.12}{Limit of a polynomial divided by an exponential}\label{f3540b0}

Let $a,b\in\R$ be fixed, with $b>1$. Then we have
$$
	\lim_{x\to\infty}\frac{x^a}{b^x}=0
$$

\begin{proof}
	Given any $\epsilon$ we want to find a $N\in\N$ such that
	$$
		n\geq N\implies\frac{x^a}{b^x}<\epsilon
	$$
	But this is equivalent to
	$$
		a\ln x-x\ln b<\ln\epsilon
	$$
	So it suffices to prove that
	$$
		a\ln x-x\ln b\to-\infty.
	$$
	Rewriting, we have
	\begin{align*}
		a\ln x-x\ln b
		 & = x\left(a\cdot\frac{\ln x}{x}-\ln b\right) \\
     & = \infty(-\ln b) \Quad\because\hyperref[e2e1632]{\frac{\ln x}{x}\to0} \\
     & = -\infty
	\end{align*}

  This completes the proof.
\end{proof}

\Theorem{2.1.1}{Fundamental theorem of calculus}\label{b869dc0}

\paragraph{First part} Let $f:[a,b]\to\R$ be continuous. Let
$F:[a,b]\to\R$ be defined by
$$F(x)=\int_a^xf(t)\,dt$$

Then $F$ is uniformly continuous on $[a,b]$ and differentiable on
$(a,b)$, and
$$F'(x)=f(x)$$

on $(a,b)$ so $F$ is an antiderivative of $f$.

\paragraph{Corollary}
$$\int_a^bf(t)\,dt=F(b)-F(a)$$

\paragraph{Second part} Let $f:[a,b]\to\R$. Let $F:[a,b]\to\R$ be
continuous and also the antiderivative of $f$ in $(a,b)$. If $f$ is
Riemann integrable on $[a,b]$, then
$$\int_a^bf(t)\,dt=F(b)-F(a)$$

This is stronger than the corollary because it does not assume that
$f$ is continuous.

\Definition{9.1.1}{Gamma function}\label{ce1fa3f}

The gamma function is defined via a convergent improper integral:
$$
	\Gamma(z):=\int_0^\infty e^{-t}t^{z-1}\,dt\Quad(\Re(z)>0)
$$

Note that ``$\displaystyle\int_0^\infty$" is a shorthand for
``$\displaystyle\lim_{k\to\infty}\int_0^k$".

Observe that $\Gamma(1)=1$.
$$\int_0^\infty e^{-t}\,dt=\Big[-e^{-t}\Big]_0^\infty=1$$

And that $\Gamma(n+1)=n\Gamma(n)$.
\begin{align*}
	\int_0^\infty e^{-t}t^n\,dt
	 & = \Big[-e^{-t}\cdot t^n\Big]_0^\infty-\int_0^\infty-e^{-t}\cdot nt^{n-1}\,dt \\
   & = 0+\int_0^\infty e^{-t}\cdot nt^{n-1}\,dt \Quad\text{(by \hyperref[f3540b0]{Result 1.1.12})} \\
	 & = n\Gamma(n)
\end{align*}