#!/usr/bin/env python3

from __utils__ import *
from __args__ import *
import os, re, time, datetime
from os import path
from subprocess import Popen, PIPE
from typing import Callable

SHOW_PROOF = False
SHOW_COMPUTE = False
MARKS = (
    b"Algorithm",
    b"Corollary",
    b"Definition",
    b"Example",
    b"Exercise",
    b"Lemma",
    b"Problem",
    b"Proposition",
    b"Remark",
    b"Result",
    b"Theorem",
)
MARKS_WITH_BSLS = tuple(b"\\" + x for x in MARKS)


def panic(*s):
    (print(*s), exit())


class Lines:  # {{{
    def __init__(self, buffer):  # type: (bytes) -> None
        self.buffer = buffer
        self.reset()
        self.hide_depth = 0

    def reset(self):
        self.cursor, self.line_number = 0, -1

    def find(self, query):  # type: (bytes) -> int
        return self.buffer.find(query, self.cursor)

    def __iter__(self):
        return self

    def __next__(self):  # type() -> tuple[bytes, int]
        if self.cursor < 0:
            self.reset()
            raise StopIteration
        self.line_number += 1
        a, b = self.cursor, self.find(b"\n")
        self.cursor = -1 if b == -1 else b + 1

        line = self.buffer[a:] if b == -1 else self.buffer[a:b]

        stripped = line.strip()

        if not SHOW_PROOF:
            if stripped == b"\\begin{proof}":
                self.hide_depth += 1
            elif stripped == b"\\end{proof}":
                self.hide_depth -= 1
                if self.hide_depth == 0:
                    return b"", self.line_number

        if not SHOW_COMPUTE:
            if stripped == b"\\begin{compute}":
                self.hide_depth += 1
            elif stripped == b"\\end{compute}":
                self.hide_depth -= 1
                if self.hide_depth == 0:
                    return b"", self.line_number

        line = b"" if self.hide_depth > 0 else line

        return line, self.line_number  # }}}


class Regex:  # {{{
    LABEL = re.compile(b"\\\\label{([a-z0-9]{7})}")
    LABEL_ENDL = re.compile(b"\\\\label{([a-z0-9]{7})}$")
    HREF = re.compile(b"\\\\href{([a-z0-9]{7})}")
    STAR_NUM = re.compile(b"^\*\[\d+\]$")  # }}}


class Line:  # {{{
    # Checks if the line closes all '{' opened in that line
    def is_closed(line):  # type: (bytes) -> bool
        stk = 0
        for b in line:
            stk += 1 if b == 123 else -1 if b == 125 else 0
        return stk == 0

    def get_mark(line):  # type: (bytes) -> bytes | None
        for st in MARKS_WITH_BSLS:
            if line.startswith(st):
                if not Line.is_closed(line):
                    panic("Section title spans multiple lines in line:\n", line)
                return st

    def get_vimgrep(line):  # type: (bytes) -> bytes | None
        if line.startswith(b"\\section"):
            return None
        num, i = get_in_between(line, 0)
        title, _ = get_in_between(line, i)
        return num + b" " + title if len(title) > 0 else num

    def get_mark_index(line):  # type: (bytes) -> bytes | None
        for i in range(len(MARKS_WITH_BSLS)):
            if line.startswith(MARKS_WITH_BSLS[i]):
                if not Line.is_closed(line):
                    panic("Section title spans multiple lines in line:\n", line)
                return i

    def get_label(line):  # type: (bytes) -> bytes | None
        """
        Assume that labels are at the end of lines.

        TODO: add to checkhealth a function that ensures that all labels
        are at the end of lines.
        """
        hit = Regex.LABEL_ENDL.search(line)
        if hit is None:
            return None
        return hit.groups()[0]  # }}}


class Index:  # {{{
    def line_number(x):
        return x[0]

    def mark(x):  # type: (tuple[int, int, bytes, bytes]) -> bytes
        return MARKS[x[1]]

    def label(x):  # type: (tuple[int, int, bytes, bytes]) -> bytes
        return x[2]  # }}}

    def title(x):  # type: (tuple[int, int, bytes, bytes]) -> bytes
        return x[3]  # }}}


class File2:  # {{{
    def __init__(self, filepath):  # type: (str) -> None
        self.filepath = filepath
        self.lines = Lines(read_file(filepath))
        self.__index__ = None  # type: list[tuple[int, int, bytes]]

    def index(self, vimgrep=False):  # type: (bool) -> None
        self.__index__ = []
        for line, k in self.lines:
            mark_index = Line.get_mark_index(line)
            label = Line.get_label(line)
            if mark_index is not None or label is not None:
                vg = None
                if vimgrep and mark_index is not None:
                    vg = Line.get_vimgrep(line)
                self.__index__.append((k, mark_index, label, vg))

    def labels(self):  # type: () -> list[bytes]
        if self.__index__ is None:
            panic(f"[{self.filepath}] is not indexed yet.")
        return list(map(Index.label, self.__index__))

    def vimgrep(self, filepath):  # type: (str) -> None
        for idx in self.__index__:
            t = Index.title(idx)
            t = filepath if t is None else t.decode("utf8")
            print(filepath, ":", Index.line_number(idx), ":", 0, ":", t, sep="")

    def add_labels_and_write(self, existing):  # type: (set[bytes]) -> None
        lines = self.lines.buffer.splitlines()
        for k, _, label in self.__index__:
            if label is None:
                lines[k] += b"\\label{" + new_sha(existing) + b"}"
        with open(self.filepath, "wb") as f:
            f.write(b"\n".join(lines))  # }}}


def new_sha(existing):  # type: (set[bytes]) -> bytes
    from random import randint as r

    s, c = "abcdef0123456789", lambda e: s[r(0, e)]
    gen = lambda: c(5) + "".join([c(15) for _ in range(6)])
    x = gen()
    while x in existing:
        x = gen()
    existing.add(x)
    return x.encode("utf-8")


def get_section_title(line):  # type: (bytes) -> bytes | None
    for st in MARKS:
        if line.startswith(b"\\" + st):
            if not section_is_one_line(line):
                print(f"[ERROR] Title spans multiple lines in line:")
                print(line)
                exit()
            return st


def get_in_between(
    buf, start, include=False
):  # type: (bytes, int, bool) -> tuple[bytes, int] | None
    stk, s = 0, None
    for i in range(start, len(buf)):
        if buf[i] == 123:  # ord(b'{')
            stk, s = stk + 1, s if s is not None else i
        elif buf[i] == 125:  # ord(b'}')
            if stk == 1:
                hit = buf[s : i + 1] if include else buf[s + 1 : i]
                return (hit, i + 1)
            stk -= 1
    return None


# Checks if the entire section title
# ```
# \Theorem{3.1.4}{Cauchy integral theorem}\label{ab0cc7c}
# ```
# is in one line by making sure all open '{' are closed.
def section_is_one_line(line):  # type: (bytes) -> bool
    stk, t = 0, {123: 1, 125: -1}
    for i in range(len(line)):
        stk += t.get(line[i], 0)
    return stk == 0


# quick routine to read a file into bytes
def read_file(path):  # type: (str) -> list[bytes]
    with open(path, "rb") as f:
        return f.read()


# lines should not end with newline characters
def write_file(path, lines):  # type: (str, list[bytes]) -> None
    with open(path, "wb") as f:
        f.write(b"\n".join(lines))


def debug():
    pass


# remove all bytes including and within a start and end marker
# remove all bytes including and within a start and end marker
def remove_in_between(data: bytes, start: bytes, end: bytes):
    buffer, n = [], len(end)
    r, p = data.find(start), 0
    while r >= 0:
        buffer.extend(data[p:r])
        p = data.find(end, r) + n
        r = data.find(start, p)
    buffer.extend(data[p:])
    return bytes(buffer)


class PdfLatex:
    # start a subprocess of `pdflatex` ready to take a latex file in
    # from stdin
    def __init__(self, args):  # type: (Args) -> None
        # tells latex compiler to search for .sty packages in this folder.
        os.environ["TEXINPUTS"] = path.join(os.curdir, "tex_modules") + ":"

        j, d = args.jobname, args.build_dir
        cmd = ("pdflatex", "-halt-on-error", f"-output-directory={d}", f"-jobname={j}")
        self.dev_mode = args.action == "dev"
        self.x = Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, env=os.environ)
        self.a = args

    # write tex contents to a file instead of stdin
    def send_to_file(self):
        self.x.kill()
        self.x.stdin = open("build.tex", "wb")

    def write(self, e: bytes):
        self.x.stdin.write(e)
        self.x.stdin.write(b"\n")

    def __compile__(self, filepath: str) -> bytes:
        b = read_file(filepath)
        if not self.a.show_computes:
            b = remove_in_between(b, b"\\begin{compute}", b"\\end{compute}")
        if not self.a.show_proofs:
            b = remove_in_between(b, b"\\begin{proof}", b"\\end{proof}")
        return b

    def generate_toc(self):
        if not self.a.toc:
            return
        self.write(b"\\section{Table of Contents}")
        pipe = map(read_file, self.a.tex_files)
        pipe = map(lambda v: v.splitlines(), pipe)

        gib = get_in_between
        w = lambda v: b"{" + v + b"}"

        for file in pipe:
            section_started = False
            for line in file:
                if not section_started and line.startswith(b"\\section"):
                    section, i = gib(line, 0, True)
                    href, _ = gib(line, i, True)
                    self.write(b"{\large " + section + b"}")
                    self.write(b"\\begin{itemize}[itemsep=0pt]\\footnotesize")
                    continue

                st = get_section_title(line)
                if st is not None:
                    num, i = gib(line, 0, False)
                    name, i = gib(line, i, True)
                    st = w(st + b" " + num)
                    href = gib(line, i, True)
                    if href is not None:
                        self.write(b"\\item[-]\\href" + href[0] + w(st + b" " + name))
                    else:
                        self.write(b"\\item[-]" + st + b" " + name)

            self.write(b"\\end{itemize}\\vspace{1em}")

    def process_files(self):
        blist = map(self.__compile__, self.a.tex_files)
        for b in blist:
            self.write(b)
            self.write(b"\\newpage")

    def run(self):
        w = self.write
        w(b"\\documentclass{article}")
        w(b"\\usepackage{" + self.a.header.encode("utf8") + b"}")
        w(b"\\begin{document}")
        self.generate_toc()
        self.process_files()
        w(b"\\end{document}")

        self.x.stdin.flush()
        self.x.stdin.close()
        if self.a.verbose:
            self.direct_stdout()
        else:
            self.filtered_stdout()
        self.x.wait()

    def buf_to_stdout(self, buf):  # type: (list[bytes]) -> None
        for l in buf:
            print(l.decode("utf8"), end="")

    def direct_stdout(self):
        self.buf_to_stdout(iter(self.x.stdout.readline, b""))

    def should_print(self, buf):  # type: (list[bytes]) -> bool
        if len(buf) == 0:
            return False
        fl = buf[0]
        if len(buf) < 2 and (b"*\n" == fl or Regex.STAR_NUM.match(fl)):
            return False
        return should_pretty_print(buf)

    def err_buf(self, buf):  # type: (list[bytes]) -> None
        s = b"".join(buf).strip().decode("utf8")
        raise Exception("PYTEX ERROR\n" + s)

    # helps to monitor stdout in a less cluttered way
    def filtered_stdout(self):
        buf, is_err = [], False
        lines = iter(self.x.stdout.readline, b"")
        lines = filter(lambda v: v.removesuffix(b"\n"), lines)
        for l in lines:
            excl, ast = l.startswith(b"!"), l.startswith(b"*")
            if excl or ast:
                if is_err and not self.dev_mode:
                    self.err_buf(buf)
                if self.should_print(buf):
                    self.buf_to_stdout(buf)
                buf.clear()
            is_err |= excl
            buf.append(l)

        if is_err and not self.dev_mode:
            self.err_buf(buf)


def merge_labels(files):  # type: (list[File2]) -> set[bytes]
    seen = set()
    for file in files:
        for label in file.labels():
            if label in seen:
                panic("Found a duplicate label: %s" % label.decode("utf8"))
            seen.add(label)
    return seen


# Get all files ending with '.tex' in the user's current directory
def get_tex_files(recursive=True):  # type: (bool) -> list[str]
    is_tex = lambda f: f.endswith(".tex")
    if recursive:
        files, cwd = [], os.curdir
        for root, _, f in os.walk(cwd):
            f = filter(is_tex, f)
            f = map(lambda f: path.join(root, f), f)
            f = map(lambda f: path.relpath(f, cwd), f)
            files.extend(f)
        return files
    else:
        return [x for x in os.listdir() if is_tex(x)]


# [SUBCOMMAND] builds using all the tex_files supplied, in that order
def __build__(args):
    if not path.isdir(args.build_dir):
        os.mkdir(args.build_dir)

    PdfLatex(args).run()

    pdf_basename = f"{args.jobname}.pdf"
    pdf_output = path.join(args.build_dir, pdf_basename)
    if path.isfile(pdf_output):
        os.rename(pdf_output, pdf_basename)


# [SUBCOMMAND] runs a server that rebuilds the pdf if any file
# changed.
def __dev__(args):
    from watchdog.events import FileSystemEventHandler

    now = lambda: datetime.datetime.now().strftime("%H:%M:%S")
    build = lambda: __build__(args)
    report = lambda: print("\x1b[33m[Last build: %s]\x1b[0m" % now())
    (build(), report())

    class EventHandler(FileSystemEventHandler):
        def __init__(self, args):
            self.args = args
            self.last_trigger_time = time.time()

        def on_modified(self, event):
            if not event.src_path.endswith(".tex"):
                return
            current_time = time.time()
            if (current_time - self.last_trigger_time) < 1:
                return
            self.last_trigger_time = current_time
            (build(), report())

    run_observer(EventHandler(args))


# [SUBCOMMAND] prints a 7-char SHA hash that the user can copy to
# clipboard. This SHA is unique in all ".tex" files that are in the
# current directory and all the current subdirectories.
#
# opinionated quirk: all generated SHAs will start with a letter.
def __sha__(_):
    files = list(map(File2, get_tex_files()))
    for file in files:
        file.index()
    all_labels = merge_labels(files)
    print(new_sha(all_labels).decode("utf8"), end="")


# [SUBCOMMAND] adds a label and a unique SHA to all marks that don't
# already have a SHA.
def __label__(_):
    files = list(map(File2, get_tex_files()))
    for file in files:
        file.index()
    all_labels = merge_labels(files)
    for file in files:
        file.add_labels_and_write(all_labels)


def __generate_section_titles__(_):
    def gen(t):  # type: (str) -> str
        c, b = lambda v: rf"\ifx&#2&\else{v}\fi", lambda v: "{" + v + "}"
        desc = c("(") + "#2" + c(")")
        return f"\def{t}#1#2" + b(
            "\subsubsection" + b(t + " {#1}\hspace{0.7em}" + b(desc))
        )

    for l in map(lambda v: gen(v.decode("utf8")), MARKS_WITH_BSLS):
        print(l)


# [SUBCOMMAND] checks if everything is in a healthy state
# 1. checks that no two labels have the same SHA
def __test__(_):
    files = list(map(File2, get_tex_files()))
    for file in files:
        file.index()
    merge_labels(files)  # should error out if duplicates are found


if __name__ == "__main__":  # int main() {
    args = Args.parse()
    tbl = {
        "build": __build__,
        "dev": __dev__,
        "sha": __sha__,
        "label": __label__,
        "generate-section-titles": __generate_section_titles__,
        "test": __test__,
    }  # type: dict[Args.Action, Callable]
    tbl[args.action](args)
